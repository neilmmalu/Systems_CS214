<?xml version="1.0" encoding="UTF-8"?>
<fileIndex>
	<word text = "a">
		<file name = "tokenizer.h">2</file>
		<file name = "tokenizer.c">12</file>
	</word>
	<word text = "access">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "according">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "addtotable">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "adir">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "after">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "all">
		<file name = "Makefile">1</file>
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "allow">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "alphanumeric">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "alphanumerics">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "alphas">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "already">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "and">
		<file name = "tokenizer.c">5</file>
	</word>
	<word text = "apparently">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "are">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "argc">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">5</file>
	</word>
	<word text = "argv">
		<file name = "tokenizer.c">7</file>
	</word>
	<word text = "as">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "at">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "b">
		<file name = "index">1</file>
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">12</file>
	</word>
	<word text = "bdir">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "be">
		<file name = "tokenizer.c">5</file>
	</word>
	<word text = "begins">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "boolean">
		<file name = "tokenizer.c">1</file>
		<file name = "tokenizer.h">2</file>
	</word>
	<word text = "both">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "break">
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "buffer">
		<file name = "tokenizer.c">12</file>
	</word>
	<word text = "c">
		<file name = "Makefile">2</file>
		<file name = "tokenizer.c">10</file>
	</word>
	<word text = "call">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "calloc">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "case">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "ccflags">
		<file name = "Makefile">1</file>
	</word>
	<word text = "cflags">
		<file name = "Makefile">1</file>
	</word>
	<word text = "change">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "char">
		<file name = "tokenizer.h">13</file>
		<file name = "tokenizer.c">20</file>
	</word>
	<word text = "check">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "checking">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "checkinput">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "checkoverwrite">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "clean">
		<file name = "Makefile">2</file>
	</word>
	<word text = "close">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "closedir">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "closeoutput">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "closing">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "collects">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "comes">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "const">
		<file name = "tokenizer.c">3</file>
		<file name = "tokenizer.h">3</file>
	</word>
	<word text = "continue">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "copies">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "could">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "count">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">20</file>
	</word>
	<word text = "counts">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "ctype">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "curr">
		<file name = "tokenizer.c">72</file>
	</word>
	<word text = "current">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "currtok">
		<file name = "tokenizer.c">8</file>
	</word>
	<word text = "d">
		<file name = "index">4</file>
		<file name = "tokenizer.c">13</file>
	</word>
	<word text = "data">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "debugging">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "default">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "delimiters">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "designated">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "destroylist">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "destroytable">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "different">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "dir">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">22</file>
	</word>
	<word text = "directory">
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "dirent">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "do">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "does">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "doesn">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "dt">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "elf">
		<file name = "index">1</file>
	</word>
	<word text = "else">
		<file name = "tokenizer.c">13</file>
	</word>
	<word text = "encoding">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "end">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "enotdir">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "ensure">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "enter">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "entry">
		<file name = "tokenizer.c">5</file>
	</word>
	<word text = "enum">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "eof">
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "errno">
		<file name = "index">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "error">
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "every">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "exist">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "existing">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "exists">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "exit">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "extend">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "f">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "false">
		<file name = "tokenizer.c">1</file>
		<file name = "tokenizer.h">2</file>
	</word>
	<word text = "few">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "fgetc">
		<file name = "index">1</file>
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "file">
		<file name = "tokenizer.h">5</file>
		<file name = "tokenizer.c">27</file>
	</word>
	<word text = "fileindex">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "filename">
		<file name = "tokenizer.h">6</file>
		<file name = "tokenizer.c">24</file>
	</word>
	<word text = "files">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "first">
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "fopen">
		<file name = "index">1</file>
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "for">
		<file name = "tokenizer.c">10</file>
	</word>
	<word text = "fprintf">
		<file name = "index">1</file>
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "free">
		<file name = "index">1</file>
		<file name = "tokenizer.c">10</file>
	</word>
	<word text = "front">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "fwrite">
		<file name = "index">1</file>
	</word>
	<word text = "garbage">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "gcc">
		<file name = "Makefile">1</file>
	</word>
	<word text = "get">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "getchar">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "ggdb">
		<file name = "Makefile">1</file>
	</word>
	<word text = "glibc">
		<file name = "index">3</file>
	</word>
	<word text = "gmon">
		<file name = "index">1</file>
	</word>
	<word text = "gnu">
		<file name = "index">2</file>
	</word>
	<word text = "h">
		<file name = "Makefile">1</file>
		<file name = "index">4</file>
		<file name = "tokenizer.h">5</file>
		<file name = "tokenizer.c">8</file>
	</word>
	<word text = "hash">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "hashtable">
		<file name = "tokenizer.h">10</file>
		<file name = "tokenizer.c">14</file>
	</word>
	<word text = "has9876568798">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "have">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "head">
		<file name = "tokenizer.h">6</file>
		<file name = "tokenizer.c">46</file>
	</word>
	<word text = "here">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "hits">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "htable">
		<file name = "tokenizer.h">4</file>
		<file name = "tokenizer.c">15</file>
	</word>
	<word text = "h0">
		<file name = "index">2</file>
	</word>
	<word text = "i">
		<file name = "index">2</file>
		<file name = "tokenizer.c">38</file>
	</word>
	<word text = "if">
		<file name = "tokenizer.c">35</file>
	</word>
	<word text = "ii">
		<file name = "index">1</file>
	</word>
	<word text = "im">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "in">
		<file name = "tokenizer.c">5</file>
	</word>
	<word text = "include">
		<file name = "tokenizer.h">5</file>
		<file name = "tokenizer.c">8</file>
	</word>
	<word text = "index">
		<file name = "Makefile">4</file>
		<file name = "tokenizer.c">15</file>
	</word>
	<word text = "individual">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "initializeoutput">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "inner">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "inputs">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "inputstring">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "inserted">
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "int">
		<file name = "tokenizer.h">8</file>
		<file name = "tokenizer.c">20</file>
	</word>
	<word text = "into">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "is">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">9</file>
	</word>
	<word text = "isalnum">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "isalpha">
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "isdigit">
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "isupper">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "it">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "itself">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "k">
		<file name = "index">2</file>
	</word>
	<word text = "keep">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "later">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "ld">
		<file name = "index">1</file>
	</word>
	<word text = "leading">
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "length">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">7</file>
	</word>
	<word text = "lengthens">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "letter">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "libc">
		<file name = "index">2</file>
	</word>
	<word text = "lib64">
		<file name = "index">1</file>
	</word>
	<word text = "like">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "linked">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "linux">
		<file name = "index">1</file>
	</word>
	<word text = "list">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">8</file>
	</word>
	<word text = "loc">
		<file name = "index">1</file>
	</word>
	<word text = "location">
		<file name = "index">1</file>
	</word>
	<word text = "long">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "longer">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "m">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "main">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "make">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "makehashtable">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "makemastertable">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "makenode">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "malloc">
		<file name = "index">1</file>
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "mallocs">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "many">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "mastertable">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "matched">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "maxnum">
		<file name = "tokenizer.c">5</file>
	</word>
	<word text = "may">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "memcpy">
		<file name = "index">1</file>
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "might">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "modified">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "move">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "mynode">
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "mytable">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">23</file>
	</word>
	<word text = "mytolower">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "n">
		<file name = "index">1</file>
		<file name = "tokenizer.c">17</file>
	</word>
	<word text = "name">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">24</file>
	</word>
	<word text = "need">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "needs">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "new">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "next">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">28</file>
	</word>
	<word text = "node">
		<file name = "tokenizer.h">2</file>
		<file name = "tokenizer.c">17</file>
	</word>
	<word text = "nodes">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "non">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "not">
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "now">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "null">
		<file name = "tokenizer.c">30</file>
	</word>
	<word text = "numbers">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "numerics">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "nu289374mbers">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "o">
		<file name = "Makefile">1</file>
	</word>
	<word text = "of">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "ok">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "on">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "one">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "open">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "opendir">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "or">
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "order">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "output">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "outputfile">
		<file name = "tokenizer.h">4</file>
		<file name = "tokenizer.c">17</file>
	</word>
	<word text = "outputinitialized">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "outputs">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "outputtokenlist">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "outputtokens">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "overwrite">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "o3ne">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "p">
		<file name = "index">1</file>
	</word>
	<word text = "path">
		<file name = "tokenizer.c">7</file>
	</word>
	<word text = "pathlength">
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "pathname">
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "pointer">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "pointers">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "pointersorter">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "prev">
		<file name = "tokenizer.c">11</file>
	</word>
	<word text = "printf">
		<file name = "tokenizer.c">16</file>
	</word>
	<word text = "printll">
		<file name = "tokenizer.c">1</file>
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "printtable">
		<file name = "tokenizer.c">1</file>
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "proceed">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "ptr">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "puts">
		<file name = "index">1</file>
	</word>
	<word text = "p0">
		<file name = "index">2</file>
	</word>
	<word text = "q">
		<file name = "index">1</file>
	</word>
	<word text = "r">
		<file name = "tokenizer.c">2</file>
		<file name = "index">3</file>
	</word>
	<word text = "readdir">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "recordnode">
		<file name = "tokenizer.h">11</file>
		<file name = "tokenizer.c">32</file>
	</word>
	<word text = "recursive">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "reg">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "regular">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "return">
		<file name = "tokenizer.c">22</file>
	</word>
	<word text = "rf">
		<file name = "Makefile">1</file>
	</word>
	<word text = "right">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "rm">
		<file name = "Makefile">1</file>
	</word>
	<word text = "s">
		<file name = "tokenizer.c">16</file>
	</word>
	<word text = "same">
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "scatters">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "scattertokens">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "second">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "sentence">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "shorter">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "should">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "size">
		<file name = "tokenizer.h">3</file>
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "sizeof">
		<file name = "tokenizer.c">7</file>
	</word>
	<word text = "skip">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "slot">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "snprintf">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "so">
		<file name = "index">2</file>
	</word>
	<word text = "something">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "sortalnum">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">7</file>
	</word>
	<word text = "sprintf">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "start">
		<file name = "index">2</file>
	</word>
	<word text = "statement">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "stdio">
		<file name = "tokenizer.c">1</file>
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "stdlib">
		<file name = "tokenizer.c">1</file>
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "step">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "strcat">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "strcmp">
		<file name = "index">1</file>
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "strdup">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "stream">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "string">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "strings">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "strlen">
		<file name = "index">1</file>
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "strncmp">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "struct">
		<file name = "tokenizer.c">1</file>
		<file name = "tokenizer.h">3</file>
	</word>
	<word text = "sure">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "switch">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "symbols">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "t">
		<file name = "index">4</file>
		<file name = "tokenizer.c">6</file>
	</word>
	<word text = "table">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">21</file>
	</word>
	<word text = "tables">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "target">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "targetfile">
		<file name = "tokenizer.c">8</file>
	</word>
	<word text = "td">
		<file name = "index">3</file>
	</word>
	<word text = "temp">
		<file name = "tokenizer.c">25</file>
	</word>
	<word text = "terminated">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "terminator">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "territory">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "test">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "text">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "the">
		<file name = "tokenizer.c">7</file>
	</word>
	<word text = "them">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "think">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "this">
		<file name = "tokenizer.h">2</file>
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "time">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "tmp">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "to">
		<file name = "tokenizer.c">12</file>
	</word>
	<word text = "tofree">
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "token">
		<file name = "tokenizer.h">2</file>
		<file name = "tokenizer.c">30</file>
	</word>
	<word text = "tokenize">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "tokenizer">
		<file name = "tokenizer.c">1</file>
		<file name = "Makefile">3</file>
	</word>
	<word text = "tokens">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "tokenstream">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "tolower">
		<file name = "index">1</file>
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "too">
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "travdir">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">4</file>
	</word>
	<word text = "true">
		<file name = "tokenizer.h">1</file>
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "txt">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "type">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "typedef">
		<file name = "tokenizer.h">3</file>
	</word>
	<word text = "u">
		<file name = "index">1</file>
	</word>
	<word text = "unistd">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "unsorted">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "until">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "ur">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "usage">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "utf">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "utilizing">
		<file name = "tokenizer.h">1</file>
	</word>
	<word text = "version">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "void">
		<file name = "tokenizer.c">12</file>
		<file name = "tokenizer.h">12</file>
	</word>
	<word text = "w">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "wall">
		<file name = "Makefile">1</file>
	</word>
	<word text = "well">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "while">
		<file name = "tokenizer.c">20</file>
	</word>
	<word text = "wish">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "with">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "word">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "wordinitialized">
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "working">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "works">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "x">
		<file name = "tokenizer.c">3</file>
	</word>
	<word text = "xml">
		<file name = "tokenizer.c">1</file>
	</word>
	<word text = "x0">
		<file name = "index">2</file>
	</word>
	<word text = "x86">
		<file name = "index">1</file>
	</word>
	<word text = "y">
		<file name = "index">1</file>
	</word>
	<word text = "you">
		<file name = "tokenizer.c">2</file>
	</word>
	<word text = "z">
		<file name = "index">1</file>
	</word>
</fileIndex>